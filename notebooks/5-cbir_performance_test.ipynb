{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9844da40",
   "metadata": {},
   "source": [
    "## Importando variáveis de ambiente\n",
    "Esse notebook prevê a existência de 2 variáveis de ambiente no arquivo .env desse projeto:\n",
    "- DATA_FOLDER\n",
    "- TRAINED_MODELS_FOLDER\n",
    "- DATASET_FOLDER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "15a8037a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv(dotenv_path=\".env\", override=True)\n",
    "\n",
    "DATA_FOLDER = os.getenv(\"DATA_FOLDER\")\n",
    "TRAINED_MODELS_FOLDER = os.getenv(\"TRAINED_MODELS_FOLDER\")\n",
    "DATASET_FOLDER = os.getenv(\"DATASET_FOLDER\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ae2480d",
   "metadata": {},
   "source": [
    "## Bibliotecas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a53dfdcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torchvision import models, transforms\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import sqlite3\n",
    "import faiss\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e472448",
   "metadata": {},
   "source": [
    "## Configurações"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8222f172",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = os.path.join(TRAINED_MODELS_FOLDER, \"best_resnet50.pth\")  # caminho do modelo treinado\n",
    "\n",
    "DB_PATH = os.path.join(DATA_FOLDER, \"metadata.db\")\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "TOP_K_CLASSES = 3\n",
    "TOP_K_RESULTS = 3   # por classe\n",
    "\n",
    "num_classes = 30"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4f08538",
   "metadata": {},
   "source": [
    "## Transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "60345b17",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                         std=[0.229, 0.224, 0.225])\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d3dd993",
   "metadata": {},
   "source": [
    "## Carrega o modelo ResNet50 para classificação e extração de características"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6c5f27f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (2): ReLU(inplace=True)\n",
       "  (3): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (4): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (5): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (6): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (4): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (5): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (7): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (8): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       ")"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = models.resnet50(weights=models.ResNet50_Weights.IMAGENET1K_V2)\n",
    "\n",
    "model.fc = torch.nn.Linear(model.fc.in_features, num_classes)\n",
    "\n",
    "model.load_state_dict(torch.load(model_path, map_location=device))\n",
    "\n",
    "model.to(device)\n",
    "model.eval()\n",
    "\n",
    "feature_extractor = nn.Sequential(*list(model.children())[:-1])\n",
    "feature_extractor.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02dbdabc",
   "metadata": {},
   "source": [
    "## Função de classificação e busca por similariadade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "af94e602",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "def classify_and_find_similar(img_path):\n",
    "    timings = {\n",
    "        \"classificacao_ms\": 0.0,\n",
    "        \"embedding_ms\": 0.0,\n",
    "        \"faiss_por_classe_ms\": {},  # {class_id: tempo_ms}\n",
    "        \"total_ms\": 0.0\n",
    "    }\n",
    "\n",
    "    # =============================\n",
    "    # Início da medição total\n",
    "    # =============================\n",
    "    t_total_start = time.perf_counter()\n",
    "\n",
    "    # 1. Conectar ao banco\n",
    "    conn = sqlite3.connect(DB_PATH)\n",
    "    cursor = conn.cursor()\n",
    "\n",
    "    # 2. Carregar imagem\n",
    "    img = Image.open(img_path).convert(\"RGB\")\n",
    "    img_tensor = transform(img).unsqueeze(0).to(device)\n",
    "\n",
    "    # =============================\n",
    "    # CLASSIFICAÇÃO\n",
    "    # =============================\n",
    "    t_class_start = time.perf_counter()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model(img_tensor)\n",
    "        probs = torch.softmax(outputs, dim=1).cpu().numpy().flatten()\n",
    "\n",
    "    t_class_end = time.perf_counter()\n",
    "\n",
    "    # 3. Obter top-K classes\n",
    "    top_classes_idx = probs.argsort()[-TOP_K_CLASSES:][::-1]\n",
    "    top_classes = []\n",
    "\n",
    "    for class_id in top_classes_idx:\n",
    "        cursor.execute(f\"SELECT name, index_path FROM class WHERE id = {class_id}\")\n",
    "        row = cursor.fetchone()\n",
    "\n",
    "        if row is None:\n",
    "            print(f\"[DEBUG][WARN] Classe {class_id} não encontrada no banco!\")\n",
    "            continue\n",
    "\n",
    "        class_name, index_path = row\n",
    "        prob = float(probs[class_id])\n",
    "\n",
    "        top_classes.append({\n",
    "            \"class_id\": class_id,\n",
    "            \"class_name\": class_name,\n",
    "            \"index_path\": index_path,\n",
    "            \"probability\": prob\n",
    "        })\n",
    "\n",
    "    # =============================\n",
    "    # EXTRAÇÃO DE EMBEDDING\n",
    "    # =============================\n",
    "    t_emb_start = time.perf_counter()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        feats = feature_extractor(img_tensor)\n",
    "        feats = feats.view(feats.size(0), -1)\n",
    "        feats = torch.nn.functional.normalize(feats, p=2, dim=1)\n",
    "        feats = feats.cpu().numpy().astype(\"float32\")\n",
    "\n",
    "    t_emb_end = time.perf_counter()\n",
    "\n",
    "    # =============================\n",
    "    # CONSULTAS FAISS\n",
    "    # =============================\n",
    "\n",
    "    similar_images = []\n",
    "\n",
    "    for cls in top_classes:\n",
    "        class_id = cls[\"class_id\"]\n",
    "\n",
    "        t_faiss_start = time.perf_counter()\n",
    "\n",
    "        faiss_index = faiss.read_index(cls[\"index_path\"])\n",
    "        distances, retrieved_ids = faiss_index.search(feats, TOP_K_RESULTS)\n",
    "\n",
    "        t_faiss_end = time.perf_counter()\n",
    "        timings[\"faiss_por_classe_ms\"][class_id] = round((t_faiss_end - t_faiss_start) * 1000, 3)\n",
    "\n",
    "        retrieved_ids = retrieved_ids[0]\n",
    "        distances = distances[0]\n",
    "\n",
    "        # Busca metadados no SQLite\n",
    "        for img_id, dist in zip(retrieved_ids, distances):\n",
    "            cursor.execute(f\"SELECT image_path FROM image WHERE id = {int(img_id)}\")\n",
    "            result = cursor.fetchone()\n",
    "\n",
    "            if result is None:\n",
    "                print(f\"[DEBUG][WARN] ID {img_id} não encontrado no banco.\")\n",
    "                continue\n",
    "            \n",
    "            image_path = result[0]\n",
    "\n",
    "            similar_images.append({\n",
    "                \"query_to_class\": cls[\"class_name\"],\n",
    "                \"retrieved_image_id\": int(img_id),\n",
    "                \"image_path\": image_path,\n",
    "                \"distance\": float(dist)\n",
    "            })\n",
    "\n",
    "    conn.close()\n",
    "\n",
    "    # Ordena por distância\n",
    "    similar_images = sorted(similar_images, key=lambda x: x[\"distance\"])\n",
    "\n",
    "    # =============================\n",
    "    # Tempo total\n",
    "    # =============================\n",
    "    t_total_end = time.perf_counter()\n",
    "    timings[\"classificacao_ms\"] = round((t_class_end - t_class_start) * 1000, 3)\n",
    "    timings[\"embedding_ms\"] = round((t_emb_end - t_emb_start) * 1000, 3)\n",
    "    timings[\"total_ms\"] = round((t_total_end - t_total_start) * 1000, 3)\n",
    "\n",
    "    # Retorna também as métricas\n",
    "    return top_classes, similar_images, timings\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a64e7861",
   "metadata": {},
   "source": [
    "## Teste de desempenho"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5e83313b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total de imagens detectadas: 7482\n",
      "Realizando warm-up...\n",
      "Warm-up concluído.\n",
      "\n",
      "Iniciando benchmark...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[17]\u001b[39m\u001b[32m, line 50\u001b[39m\n\u001b[32m     47\u001b[39m start_wall = time.perf_counter()\n\u001b[32m     49\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i, img_path \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(all_images, \u001b[32m1\u001b[39m):\n\u001b[32m---> \u001b[39m\u001b[32m50\u001b[39m     classes, results, timings = \u001b[43mclassify_and_find_similar\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     52\u001b[39m     \u001b[38;5;66;03m# LATÊNCIAS GLOBAIS\u001b[39;00m\n\u001b[32m     53\u001b[39m     lat_total.append(timings[\u001b[33m\"\u001b[39m\u001b[33mtotal_ms\u001b[39m\u001b[33m\"\u001b[39m])\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[13]\u001b[39m\u001b[32m, line 63\u001b[39m, in \u001b[36mclassify_and_find_similar\u001b[39m\u001b[34m(img_path)\u001b[39m\n\u001b[32m     60\u001b[39m t_emb_start = time.perf_counter()\n\u001b[32m     62\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m torch.no_grad():\n\u001b[32m---> \u001b[39m\u001b[32m63\u001b[39m     feats = \u001b[43mfeature_extractor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg_tensor\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     64\u001b[39m     feats = feats.view(feats.size(\u001b[32m0\u001b[39m), -\u001b[32m1\u001b[39m)\n\u001b[32m     65\u001b[39m     feats = torch.nn.functional.normalize(feats, p=\u001b[32m2\u001b[39m, dim=\u001b[32m1\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documentos/Prog_Projects/cnn_peixes/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1775\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1774\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1775\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documentos/Prog_Projects/cnn_peixes/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1786\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1781\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1782\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1783\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1784\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1785\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1786\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1788\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1789\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documentos/Prog_Projects/cnn_peixes/.venv/lib/python3.12/site-packages/torch/nn/modules/container.py:250\u001b[39m, in \u001b[36mSequential.forward\u001b[39m\u001b[34m(self, input)\u001b[39m\n\u001b[32m    246\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    247\u001b[39m \u001b[33;03mRuns the forward pass.\u001b[39;00m\n\u001b[32m    248\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    249\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m250\u001b[39m     \u001b[38;5;28minput\u001b[39m = \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    251\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documentos/Prog_Projects/cnn_peixes/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1775\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1774\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1775\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documentos/Prog_Projects/cnn_peixes/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1786\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1781\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1782\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1783\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1784\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1785\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1786\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1788\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1789\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documentos/Prog_Projects/cnn_peixes/.venv/lib/python3.12/site-packages/torch/nn/modules/container.py:250\u001b[39m, in \u001b[36mSequential.forward\u001b[39m\u001b[34m(self, input)\u001b[39m\n\u001b[32m    246\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    247\u001b[39m \u001b[33;03mRuns the forward pass.\u001b[39;00m\n\u001b[32m    248\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    249\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m250\u001b[39m     \u001b[38;5;28minput\u001b[39m = \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    251\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documentos/Prog_Projects/cnn_peixes/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1775\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1774\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1775\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documentos/Prog_Projects/cnn_peixes/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1786\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1781\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1782\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1783\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1784\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1785\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1786\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1788\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1789\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documentos/Prog_Projects/cnn_peixes/.venv/lib/python3.12/site-packages/torchvision/models/resnet.py:161\u001b[39m, in \u001b[36mBottleneck.forward\u001b[39m\u001b[34m(self, x)\u001b[39m\n\u001b[32m    158\u001b[39m     identity = \u001b[38;5;28mself\u001b[39m.downsample(x)\n\u001b[32m    160\u001b[39m out += identity\n\u001b[32m--> \u001b[39m\u001b[32m161\u001b[39m out = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mrelu\u001b[49m(out)\n\u001b[32m    163\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m out\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documentos/Prog_Projects/cnn_peixes/.venv/lib/python3.12/site-packages/torch/nn/modules/module.py:1951\u001b[39m, in \u001b[36mModule.__getattr__\u001b[39m\u001b[34m(self, name)\u001b[39m\n\u001b[32m   1946\u001b[39m         \u001b[38;5;28mself\u001b[39m._backward_pre_hooks = OrderedDict()\n\u001b[32m   1948\u001b[39m \u001b[38;5;66;03m# It is crucial that the return type is not annotated as `Any`, otherwise type checking\u001b[39;00m\n\u001b[32m   1949\u001b[39m \u001b[38;5;66;03m# on `torch.nn.Module` and all its subclasses is largely disabled as a result. See:\u001b[39;00m\n\u001b[32m   1950\u001b[39m \u001b[38;5;66;03m# https://github.com/pytorch/pytorch/pull/115074\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1951\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__getattr__\u001b[39m(\u001b[38;5;28mself\u001b[39m, name: \u001b[38;5;28mstr\u001b[39m) -> Union[Tensor, \u001b[33m\"\u001b[39m\u001b[33mModule\u001b[39m\u001b[33m\"\u001b[39m]:\n\u001b[32m   1952\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33m_parameters\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.\u001b[34m__dict__\u001b[39m:\n\u001b[32m   1953\u001b[39m         _parameters = \u001b[38;5;28mself\u001b[39m.\u001b[34m__dict__\u001b[39m[\u001b[33m\"\u001b[39m\u001b[33m_parameters\u001b[39m\u001b[33m\"\u001b[39m]\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# ---------------------------------------------------------\n",
    "# CONFIG\n",
    "# ---------------------------------------------------------\n",
    "TEST_ROOT = DATASET_FOLDER   # raiz contendo subpastas por classe\n",
    "\n",
    "valid_ext = (\".jpg\", \".jpeg\", \".png\", \".bmp\", \".webp\")\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# LISTAR TODAS AS IMAGENS (com subpastas)\n",
    "# ---------------------------------------------------------\n",
    "all_images = []\n",
    "\n",
    "for root, dirs, files in os.walk(TEST_ROOT):\n",
    "    for f in files:\n",
    "        if f.lower().endswith(valid_ext):\n",
    "            all_images.append(os.path.join(root, f))\n",
    "\n",
    "print(f\"Total de imagens detectadas: {len(all_images)}\")\n",
    "\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# ESTRUTURAS PARA COLETA DE MÉTRICAS\n",
    "# ---------------------------------------------------------\n",
    "lat_total = []\n",
    "lat_class = []\n",
    "lat_emb = []\n",
    "lat_faiss_total = []\n",
    "\n",
    "lat_por_classe = defaultdict(list)\n",
    "faiss_por_classe = defaultdict(list)\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# WARM UP DE GPU (IMPORTANTE!)\n",
    "# ---------------------------------------------------------\n",
    "print(\"Realizando warm-up...\")\n",
    "for _ in range(3):\n",
    "    classify_and_find_similar(all_images[0])\n",
    "\n",
    "print(\"Warm-up concluído.\")\n",
    "\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# EXECUTAR BENCHMARK\n",
    "# ---------------------------------------------------------\n",
    "print(\"\\nIniciando benchmark...\")\n",
    "\n",
    "start_wall = time.perf_counter()\n",
    "\n",
    "for i, img_path in enumerate(all_images, 1):\n",
    "    classes, results, timings = classify_and_find_similar(img_path)\n",
    "\n",
    "    # LATÊNCIAS GLOBAIS\n",
    "    lat_total.append(timings[\"total_ms\"])\n",
    "    lat_class.append(timings[\"classificacao_ms\"])\n",
    "    lat_emb.append(timings[\"embedding_ms\"])\n",
    "\n",
    "    # FAISS total por consulta\n",
    "    faiss_sum = sum(timings[\"faiss_por_classe_ms\"].values())\n",
    "    lat_faiss_total.append(faiss_sum)\n",
    "\n",
    "    # MÉTRICAS POR CLASSE PREVISTA (top-1)\n",
    "    if classes:\n",
    "        c = classes[0][\"class_name\"]\n",
    "        lat_por_classe[c].append(timings[\"total_ms\"])\n",
    "        faiss_por_classe[c].append(faiss_sum)\n",
    "\n",
    "end_wall = time.perf_counter()\n",
    "\n",
    "print(\"Benchmark concluído.\")\n",
    "\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# THROUGHPUT\n",
    "# ---------------------------------------------------------\n",
    "tempo_total_benchmark_s = end_wall - start_wall\n",
    "throughput_qps = len(all_images) / tempo_total_benchmark_s\n",
    "\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# RESUMO GLOBAL\n",
    "# ---------------------------------------------------------\n",
    "def resumo(nome, arr):\n",
    "    arr = np.array(arr)\n",
    "    print(f\"\\n=== {nome} ===\")\n",
    "    print(f\"Média:     {arr.mean():.2f} ms\")\n",
    "    print(f\"Mediana:   {np.median(arr):.2f} ms\")\n",
    "    print(f\"P90:       {np.percentile(arr, 90):.2f} ms\")\n",
    "    print(f\"P95:       {np.percentile(arr, 95):.2f} ms\")\n",
    "    print(f\"P99:       {np.percentile(arr, 99):.2f} ms\")\n",
    "    print(f\"Mínimo:    {arr.min():.2f} ms\")\n",
    "    print(f\"Máximo:    {arr.max():.2f} ms\")\n",
    "\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# IMPRIMIR RESULTADOS\n",
    "# ---------------------------------------------------------\n",
    "print(\"\\n===================================================\")\n",
    "print(\"                 RESULTADOS GERAIS                 \")\n",
    "print(\"===================================================\\n\")\n",
    "\n",
    "resumo(\"Latência TOTAL da query\", lat_total)\n",
    "resumo(\"Latência da classificação\", lat_class)\n",
    "resumo(\"Latência do embedding\", lat_emb)\n",
    "resumo(\"Latência FAISS (somada)\", lat_faiss_total)\n",
    "\n",
    "print(\"\\n---------------------------------------------------\")\n",
    "print(f\"THROUGHPUT: {throughput_qps:.2f} queries/segundo\")\n",
    "print(\"---------------------------------------------------\")\n",
    "\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# RANKING DAS ETAPAS POR CUSTO MÉDIO\n",
    "# ---------------------------------------------------------\n",
    "print(\"\\n\\n=== Ranking das etapas mais custosas (média ms) ===\")\n",
    "\n",
    "etapas = {\n",
    "    \"Classificação\": np.mean(lat_class),\n",
    "    \"Embedding\": np.mean(lat_emb),\n",
    "    \"FAISS\": np.mean(lat_faiss_total),\n",
    "}\n",
    "\n",
    "for etapa, valor in sorted(etapas.items(), key=lambda x: x[1], reverse=True):\n",
    "    print(f\"{etapa}: {valor:.2f} ms\")\n",
    "\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# HISTOGRAMA DA LATÊNCIA TOTAL\n",
    "# ---------------------------------------------------------\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.hist(lat_total, bins=40, alpha=0.75)\n",
    "plt.title(\"Histograma da Latência Total\")\n",
    "plt.xlabel(\"Latência (ms)\")\n",
    "plt.ylabel(\"Frequência\")\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# LATÊNCIA POR CLASSE (TOP-1)\n",
    "# ---------------------------------------------------------\n",
    "media_por_classe = {cls: np.mean(vals) for cls, vals in lat_por_classe.items()}\n",
    "ordenado = sorted(media_por_classe.items(), key=lambda x: x[1])\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.bar([c for c, _ in ordenado], [v for _, v in ordenado])\n",
    "plt.xticks(rotation=80)\n",
    "plt.title(\"Latência Média por Classe (TOP-1 prev)\")\n",
    "plt.ylabel(\"Latência (ms)\")\n",
    "plt.grid(True, axis=\"y\")\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
