{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "401b64ef",
   "metadata": {},
   "source": [
    "## Importando variáveis de ambiente\n",
    "Esse notebook prevê a existência de 2 variáveis de ambiente no arquivo .env desse projeto:\n",
    "- DATA_FOLDER\n",
    "- TEST_DATA_FOLDER\n",
    "- TRAINED_MODELS_FOLDER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ef2d7e59",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv(dotenv_path=\".env\", override=True)\n",
    "\n",
    "DATA_FOLDER = os.getenv(\"DATA_FOLDER\")\n",
    "TEST_DATA_FOLDER = os.getenv(\"TEST_DATA_FOLDER\")\n",
    "TRAINED_MODELS_FOLDER = os.getenv(\"TRAINED_MODELS_FOLDER\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdf3f2d5",
   "metadata": {},
   "source": [
    "## Bibliotecas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "75879597",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torchvision import models, transforms\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import sqlite3\n",
    "import faiss\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c86bc880",
   "metadata": {},
   "source": [
    "## Configurações"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e63eab1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = os.path.join(TRAINED_MODELS_FOLDER, \"best_resnet50.pth\")  # caminho do modelo treinado\n",
    "\n",
    "DB_PATH = os.path.join(DATA_FOLDER, \"metadata.db\")\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "TOP_K_CLASSES = 3\n",
    "TOP_K_RESULTS = 3   # por classe\n",
    "\n",
    "num_classes = 30"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9ca208e",
   "metadata": {},
   "source": [
    "## Transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a6fadbed",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                         std=[0.229, 0.224, 0.225])\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "053a6a57",
   "metadata": {},
   "source": [
    "## Carrega o modelo ResNet50 para classificação e extração de características"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "226f3138",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (2): ReLU(inplace=True)\n",
       "  (3): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (4): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (5): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (6): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (4): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (5): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (7): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (8): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = models.resnet50(weights=models.ResNet50_Weights.IMAGENET1K_V2)\n",
    "\n",
    "model.fc = torch.nn.Linear(model.fc.in_features, num_classes)\n",
    "\n",
    "model.load_state_dict(torch.load(model_path, map_location=device))\n",
    "\n",
    "model.to(device)\n",
    "model.eval()\n",
    "\n",
    "feature_extractor = nn.Sequential(*list(model.children())[:-1])\n",
    "feature_extractor.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38e3c96d",
   "metadata": {},
   "source": [
    "## Função de classificação e busca por similariadade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d83dab21",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "def classify_and_find_similar(img_path):\n",
    "    timings = {\n",
    "        \"classificacao_ms\": 0.0,\n",
    "        \"embedding_ms\": 0.0,\n",
    "        \"faiss_por_classe_ms\": {},  # {class_id: tempo_ms}\n",
    "        \"total_ms\": 0.0\n",
    "    }\n",
    "\n",
    "    # =============================\n",
    "    # Início da medição total\n",
    "    # =============================\n",
    "    t_total_start = time.perf_counter()\n",
    "\n",
    "    # 1. Conectar ao banco\n",
    "    conn = sqlite3.connect(DB_PATH)\n",
    "    cursor = conn.cursor()\n",
    "\n",
    "    # 2. Carregar imagem\n",
    "    img = Image.open(img_path).convert(\"RGB\")\n",
    "    img_tensor = transform(img).unsqueeze(0).to(device)\n",
    "\n",
    "    # =============================\n",
    "    # CLASSIFICAÇÃO\n",
    "    # =============================\n",
    "    t_class_start = time.perf_counter()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model(img_tensor)\n",
    "        probs = torch.softmax(outputs, dim=1).cpu().numpy().flatten()\n",
    "\n",
    "    t_class_end = time.perf_counter()\n",
    "\n",
    "    # 3. Obter top-K classes\n",
    "    top_classes_idx = probs.argsort()[-TOP_K_CLASSES:][::-1]\n",
    "    top_classes = []\n",
    "\n",
    "    for class_id in top_classes_idx:\n",
    "        cursor.execute(f\"SELECT name, index_path FROM class WHERE id = {class_id}\")\n",
    "        row = cursor.fetchone()\n",
    "\n",
    "        if row is None:\n",
    "            print(f\"[DEBUG][WARN] Classe {class_id} não encontrada no banco!\")\n",
    "            continue\n",
    "\n",
    "        class_name, index_path = row\n",
    "        prob = float(probs[class_id])\n",
    "\n",
    "        top_classes.append({\n",
    "            \"class_id\": class_id,\n",
    "            \"class_name\": class_name,\n",
    "            \"index_path\": index_path,\n",
    "            \"probability\": prob\n",
    "        })\n",
    "\n",
    "    # =============================\n",
    "    # EXTRAÇÃO DE EMBEDDING\n",
    "    # =============================\n",
    "    t_emb_start = time.perf_counter()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        feats = feature_extractor(img_tensor)\n",
    "        feats = feats.view(feats.size(0), -1)\n",
    "        feats = torch.nn.functional.normalize(feats, p=2, dim=1)\n",
    "        feats = feats.cpu().numpy().astype(\"float32\")\n",
    "\n",
    "    t_emb_end = time.perf_counter()\n",
    "\n",
    "    # =============================\n",
    "    # CONSULTAS FAISS\n",
    "    # =============================\n",
    "\n",
    "    similar_images = []\n",
    "\n",
    "    for cls in top_classes:\n",
    "        class_id = cls[\"class_id\"]\n",
    "\n",
    "        t_faiss_start = time.perf_counter()\n",
    "\n",
    "        faiss_index = faiss.read_index(cls[\"index_path\"])\n",
    "        distances, retrieved_ids = faiss_index.search(feats, TOP_K_RESULTS)\n",
    "\n",
    "        t_faiss_end = time.perf_counter()\n",
    "        timings[\"faiss_por_classe_ms\"][class_id] = round((t_faiss_end - t_faiss_start) * 1000, 3)\n",
    "\n",
    "        retrieved_ids = retrieved_ids[0]\n",
    "        distances = distances[0]\n",
    "\n",
    "        # Busca metadados no SQLite\n",
    "        for img_id, dist in zip(retrieved_ids, distances):\n",
    "            cursor.execute(f\"SELECT image_path FROM image WHERE id = {int(img_id)}\")\n",
    "            result = cursor.fetchone()\n",
    "\n",
    "            if result is None:\n",
    "                print(f\"[DEBUG][WARN] ID {img_id} não encontrado no banco.\")\n",
    "                continue\n",
    "            \n",
    "            image_path = result[0]\n",
    "\n",
    "            similar_images.append({\n",
    "                \"query_to_class\": cls[\"class_name\"],\n",
    "                \"retrieved_image_id\": int(img_id),\n",
    "                \"image_path\": image_path,\n",
    "                \"distance\": float(dist)\n",
    "            })\n",
    "\n",
    "    conn.close()\n",
    "\n",
    "    # Ordena por distância\n",
    "    similar_images = sorted(similar_images, key=lambda x: x[\"distance\"])\n",
    "\n",
    "    # =============================\n",
    "    # Tempo total\n",
    "    # =============================\n",
    "    t_total_end = time.perf_counter()\n",
    "    timings[\"classificacao_ms\"] = round((t_class_end - t_class_start) * 1000, 3)\n",
    "    timings[\"embedding_ms\"] = round((t_emb_end - t_emb_start) * 1000, 3)\n",
    "    timings[\"total_ms\"] = round((t_total_end - t_total_start) * 1000, 3)\n",
    "\n",
    "    # Retorna também as métricas\n",
    "    return top_classes, similar_images, timings\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33018259",
   "metadata": {},
   "source": [
    "## Função para exibir os resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cece576e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_results(query_image_path, classes, results, save_png=False, png_path=\"comparacao.png\"):\n",
    "    print(\"\\n=== Exibindo resultados avançados ===\")\n",
    "\n",
    "    # ------------------------------------------------------\n",
    "    # 1. Mostrar imagem de entrada\n",
    "    # ------------------------------------------------------\n",
    "    query_img = Image.open(query_image_path).convert(\"RGB\")\n",
    "\n",
    "    plt.figure(figsize=(6,6))\n",
    "    plt.imshow(query_img)\n",
    "    plt.axis(\"off\")\n",
    "    plt.title(\"Imagem de entrada (query)\", fontsize=16)\n",
    "    plt.show()\n",
    "\n",
    "    # ------------------------------------------------------\n",
    "    # 2. Determinar ranking das classes\n",
    "    # ------------------------------------------------------\n",
    "    ranked_classes = sorted(classes, key=lambda x: x[\"probability\"], reverse=True)\n",
    "\n",
    "    # Criar mapa class_name → (rank, prob)\n",
    "    rank_map = {}\n",
    "    for idx, c in enumerate(ranked_classes):\n",
    "        rank_map[c[\"class_name\"]] = {\n",
    "            \"rank\": idx + 1,\n",
    "            \"prob\": c[\"probability\"]\n",
    "        }\n",
    "\n",
    "    # Cores por ranking\n",
    "    rank_colors = {\n",
    "        1: \"blue\",\n",
    "        2: \"darkorange\",\n",
    "        3: \"gray\"\n",
    "    }\n",
    "\n",
    "    # ------------------------------------------------------\n",
    "    # 3. Imprimir Top-K Classes como resumo texto\n",
    "    # ------------------------------------------------------\n",
    "    print(\"\\n=== Top Classes ===\")\n",
    "    for c in ranked_classes:\n",
    "        r = rank_map[c[\"class_name\"]][\"rank\"]\n",
    "        p = rank_map[c[\"class_name\"]][\"prob\"] * 100\n",
    "        print(f\"[Rank {r}] {c['class_name']} — {p:.4f}%\")\n",
    "\n",
    "    # ------------------------------------------------------\n",
    "    # 4. Agrupar resultados por classe\n",
    "    # ------------------------------------------------------\n",
    "    grouped = {}\n",
    "    for r in results:\n",
    "        cls = r[\"query_to_class\"]\n",
    "        if cls not in grouped:\n",
    "            grouped[cls] = []\n",
    "        grouped[cls].append(r)\n",
    "\n",
    "    # ------------------------------------------------------\n",
    "    # 5. Visualizar cada classe com ranking, probabilidade e grid\n",
    "    # ------------------------------------------------------\n",
    "    for cls_name, images in grouped.items():\n",
    "\n",
    "        info = rank_map.get(cls_name, None)\n",
    "\n",
    "        if info:\n",
    "            rank = info[\"rank\"]\n",
    "            prob = info[\"prob\"] * 100\n",
    "            rank_suffix = f\" (Rank {rank} — {prob:.3f}%)\"\n",
    "            color = rank_colors.get(rank, \"black\")\n",
    "        else:\n",
    "            rank_suffix = \"\"\n",
    "            color = \"black\"\n",
    "\n",
    "        print(f\"\\n=== Classe: {cls_name}{rank_suffix} ===\")\n",
    "\n",
    "        images_sorted = sorted(images, key=lambda x: x[\"distance\"])\n",
    "\n",
    "        cols = 3\n",
    "        rows = math.ceil(len(images_sorted) / cols)\n",
    "\n",
    "        # ATIVA um layout mais inteligente\n",
    "        fig, axes = plt.subplots(\n",
    "            rows,\n",
    "            cols,\n",
    "            figsize=(6*cols, 4*rows),\n",
    "            constrained_layout=True\n",
    "        )\n",
    "\n",
    "        # Permite titles sem serem cobertos\n",
    "        fig.subplots_adjust(top=0.90)\n",
    "\n",
    "        # Para aceitar casos com apenas 1 linha\n",
    "        if rows == 1:\n",
    "            axes = [axes]\n",
    "        if cols == 1:\n",
    "            axes = [[ax] for ax in axes]\n",
    "\n",
    "        fig.suptitle(f\"{cls_name}{rank_suffix}\", fontsize=18, color=color)\n",
    "\n",
    "        for i, item in enumerate(images_sorted):\n",
    "            r = i // cols\n",
    "            c = i % cols\n",
    "            ax = axes[r][c]\n",
    "\n",
    "            try:\n",
    "                simg = Image.open(item[\"image_path\"]).convert(\"RGB\")\n",
    "            except:\n",
    "                ax.axis(\"off\")\n",
    "                continue\n",
    "\n",
    "            ax.imshow(simg)\n",
    "            ax.axis(\"off\")\n",
    "\n",
    "            # Destacar match exato\n",
    "            if item[\"distance\"] == 0.0:\n",
    "                ax.set_title(\n",
    "                    f\"[MATCH EXATO]\\nID: {item['retrieved_image_id']} | Dist: 0.0\",\n",
    "                    fontsize=12,\n",
    "                    color=\"green\",\n",
    "                    fontweight=\"bold\"\n",
    "                )\n",
    "                for side in ax.spines:\n",
    "                    ax.spines[side].set_color(\"green\")\n",
    "                    ax.spines[side].set_linewidth(3)\n",
    "            else:\n",
    "                ax.set_title(\n",
    "                    f\"ID: {item['retrieved_image_id']}\\nDist: {item['distance']:.4f}\",\n",
    "                    fontsize=11\n",
    "                )\n",
    "\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "    # ------------------------------------------------------\n",
    "    # 6. PNG único com painel geral (opcional)\n",
    "    # ------------------------------------------------------\n",
    "    if save_png:\n",
    "        print(f\"[DEBUG] Salvando comparacao em PNG: {png_path}\")\n",
    "\n",
    "        all_imgs = results[:]\n",
    "        cols = 4\n",
    "        rows = math.ceil(len(all_imgs) / cols)\n",
    "\n",
    "        fig = plt.figure(figsize=(5*cols, 4*rows))\n",
    "        fig.suptitle(\"Comparação completa\", fontsize=18)\n",
    "\n",
    "        for i, r in enumerate(all_imgs):\n",
    "            ax = plt.subplot(rows, cols, i+1)\n",
    "            simg = Image.open(r[\"image_path\"]).convert(\"RGB\")\n",
    "            ax.imshow(simg)\n",
    "            ax.axis(\"off\")\n",
    "            ax.set_title(f\"{r['query_to_class']} | {r['distance']:.3f}\", fontsize=10)\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.subplots_adjust(top=0.92)\n",
    "        fig.savefig(png_path, dpi=180)\n",
    "        print(f\"[OK] PNG salvo em: {png_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2db0c094",
   "metadata": {},
   "source": [
    "## Testando o CBIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6f98e0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from ipywidgets import Button, HBox, VBox, Output\n",
    "from IPython.display import display, clear_output\n",
    "\n",
    "def run_batch_visualization_notebook(test_folder):\n",
    "    valid_ext = (\".jpg\", \".jpeg\", \".png\", \".bmp\", \".webp\")\n",
    "    \n",
    "    image_files = sorted([\n",
    "        f for f in os.listdir(test_folder)\n",
    "        if f.lower().endswith(valid_ext)\n",
    "    ])\n",
    "\n",
    "    if not image_files:\n",
    "        print(\"Nenhuma imagem encontrada.\")\n",
    "        return\n",
    "\n",
    "    index = {\"i\": 0}  # índice compartilhado entre callbacks\n",
    "    out = Output()\n",
    "\n",
    "    # Botões\n",
    "    btn_prev = Button(description=\"← Anterior\", button_style=\"warning\", layout={\"width\": \"150px\"})\n",
    "    btn_next = Button(description=\"Próxima →\", button_style=\"info\", layout={\"width\": \"150px\"})\n",
    "\n",
    "    # ----------------------\n",
    "    # Renderizar imagem atual\n",
    "    # ----------------------\n",
    "    def show_current():\n",
    "        with out:\n",
    "            clear_output(wait=True)\n",
    "\n",
    "            i = index[\"i\"]\n",
    "            filename = image_files[i]\n",
    "            img_path = os.path.join(test_folder, filename)\n",
    "\n",
    "            print(f\"[{i+1}/{len(image_files)}] Classificando: {filename}\")\n",
    "\n",
    "            classes, results = classify_and_find_similar(img_path)\n",
    "\n",
    "            show_results(\n",
    "                query_image_path=img_path,\n",
    "                classes=classes,\n",
    "                results=results\n",
    "            )\n",
    "\n",
    "    # ----------------------\n",
    "    # BOTÃO PRÓXIMA\n",
    "    # ----------------------\n",
    "    def on_next(b):\n",
    "        if index[\"i\"] < len(image_files) - 1:\n",
    "            index[\"i\"] += 1\n",
    "            show_current()\n",
    "        else:\n",
    "            with out:\n",
    "                clear_output(wait=True)\n",
    "                print(\"Fim da lista de imagens.\")\n",
    "\n",
    "    # ----------------------\n",
    "    # BOTÃO ANTERIOR\n",
    "    # ----------------------\n",
    "    def on_prev(b):\n",
    "        if index[\"i\"] > 0:\n",
    "            index[\"i\"] -= 1\n",
    "            show_current()\n",
    "        else:\n",
    "            with out:\n",
    "                clear_output(wait=True)\n",
    "                print(\"Você já está na primeira imagem.\")\n",
    "\n",
    "    # Liga os eventos\n",
    "    btn_prev.on_click(on_prev)\n",
    "    btn_next.on_click(on_next)\n",
    "\n",
    "    # Interface\n",
    "    display(VBox([\n",
    "        HBox([btn_prev, btn_next]),\n",
    "        out\n",
    "    ]))\n",
    "\n",
    "    # Mostrar a primeira imagem\n",
    "    show_current()\n",
    "\n",
    "\n",
    "# Executar\n",
    "import os\n",
    "from ipywidgets import Button, HBox, VBox, Output\n",
    "from IPython.display import display, clear_output\n",
    "\n",
    "def run_batch_visualization_notebook(test_folder):\n",
    "    valid_ext = (\".jpg\", \".jpeg\", \".png\", \".bmp\", \".webp\")\n",
    "    \n",
    "    image_files = sorted([\n",
    "        f for f in os.listdir(test_folder)\n",
    "        if f.lower().endswith(valid_ext)\n",
    "    ])\n",
    "\n",
    "    if not image_files:\n",
    "        print(\"Nenhuma imagem encontrada.\")\n",
    "        return\n",
    "\n",
    "    index = {\"i\": 0}  # índice compartilhado entre callbacks\n",
    "    out = Output()\n",
    "\n",
    "    # Botões\n",
    "    btn_prev = Button(description=\"← Anterior\", button_style=\"warning\", layout={\"width\": \"150px\"})\n",
    "    btn_next = Button(description=\"Próxima →\", button_style=\"info\", layout={\"width\": \"150px\"})\n",
    "\n",
    "    # ----------------------\n",
    "    # Renderizar imagem atual\n",
    "    # ----------------------\n",
    "    def show_current():\n",
    "        with out:\n",
    "            clear_output(wait=True)\n",
    "\n",
    "            i = index[\"i\"]\n",
    "            filename = image_files[i]\n",
    "            img_path = os.path.join(test_folder, filename)\n",
    "\n",
    "            print(f\"[{i+1}/{len(image_files)}] Classificando: {filename}\")\n",
    "\n",
    "            classes, results, metrics = classify_and_find_similar(img_path)\n",
    "\n",
    "            # Exibe o tempo de query\n",
    "            print(\"Tempo total:\", metrics[\"total_ms\"], \"ms\")\n",
    "            print(\"Classificação:\", metrics[\"classificacao_ms\"], \"ms\")\n",
    "            print(\"Embedding:\", metrics[\"embedding_ms\"], \"ms\")\n",
    "            print(\"FAISS por classe:\")\n",
    "            for class_id, t_ms in metrics[\"faiss_por_classe_ms\"].items():\n",
    "                print(f\"  Classe {class_id}: {t_ms} ms\")\n",
    "\n",
    "            show_results(\n",
    "                query_image_path=img_path,\n",
    "                classes=classes,\n",
    "                results=results\n",
    "            )\n",
    "\n",
    "    # ----------------------\n",
    "    # BOTÃO PRÓXIMA\n",
    "    # ----------------------\n",
    "    def on_next(b):\n",
    "        if index[\"i\"] < len(image_files) - 1:\n",
    "            index[\"i\"] += 1\n",
    "            show_current()\n",
    "        else:\n",
    "            with out:\n",
    "                clear_output(wait=True)\n",
    "                print(\"Fim da lista de imagens.\")\n",
    "\n",
    "    # ----------------------\n",
    "    # BOTÃO ANTERIOR\n",
    "    # ----------------------\n",
    "    def on_prev(b):\n",
    "        if index[\"i\"] > 0:\n",
    "            index[\"i\"] -= 1\n",
    "            show_current()\n",
    "        else:\n",
    "            with out:\n",
    "                clear_output(wait=True)\n",
    "                print(\"Você já está na primeira imagem.\")\n",
    "\n",
    "    # Liga os eventos\n",
    "    btn_prev.on_click(on_prev)\n",
    "    btn_next.on_click(on_next)\n",
    "\n",
    "    # Interface\n",
    "    display(VBox([\n",
    "        HBox([btn_prev, btn_next]),\n",
    "        out\n",
    "    ]))\n",
    "\n",
    "    # Mostrar a primeira imagem\n",
    "    show_current()\n",
    "\n",
    "\n",
    "# Executar\n",
    "run_batch_visualization_notebook(TEST_DATA_FOLDER)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
