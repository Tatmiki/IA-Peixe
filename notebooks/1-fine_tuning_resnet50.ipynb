{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "859d5c75",
   "metadata": {},
   "source": [
    "## Importando variáveis de ambiente\n",
    "Esse notebook prevê a existência de 2 variáveis de ambiente no arquivo .env desse projeto:\n",
    "- DATA_FOLDER\n",
    "- TRAINED_MODELS_FOLDER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac7d8cb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv(dotenv_path=\".env\")\n",
    "\n",
    "DATA_FOLDER = os.getenv(\"DATA_FOLDER\")\n",
    "TRAINED_MODELS_FOLDER = os.getenv(\"TRAINED_MODELS_FOLDER\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8136a4f",
   "metadata": {},
   "source": [
    "## Bibliotecas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9614838f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import models, transforms, datasets\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d26190d",
   "metadata": {},
   "source": [
    "## Transforms (data augmentation online para o treino)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d8b5ab40",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_SIZE = 224 # trabalha com imagens 224x224 com 3 canais RGB, as transforms colocarão as imagens nesse padrão\n",
    "\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.Resize((IMG_SIZE, IMG_SIZE)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(10),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                         std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "val_transform = transforms.Compose([\n",
    "    transforms.Resize((IMG_SIZE, IMG_SIZE)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], #normaliza os canais R, G e B da imagem para a ResNet50 ImageNet\n",
    "                         std=[0.229, 0.224, 0.225]),\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3356c455",
   "metadata": {},
   "source": [
    "## Datasets e DataLoaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7d211f41",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image, UnidentifiedImageError\n",
    "\n",
    "def safe_loader(path):\n",
    "    try:\n",
    "        return Image.open(path).convert(\"RGB\")\n",
    "    except UnidentifiedImageError:\n",
    "        print(f\"[ERRO] Imagem corrompida ignorada: {path}\")\n",
    "        # retorna uma imagem branca 224x224 (não quebra o DataLoader)\n",
    "        return Image.new(\"RGB\", (224, 224), (255, 255, 255))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42224f3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total de classes: 30\n"
     ]
    }
   ],
   "source": [
    "data_dir = os.path.join(DATA_FOLDER, 'splits')\n",
    "\n",
    "train_ds = datasets.ImageFolder(os.path.join(data_dir, \"train\"), transform=train_transform, loader=safe_loader) # shuffle evita aprender ordem\n",
    "val_ds   = datasets.ImageFolder(os.path.join(data_dir, \"val\"),   transform=val_transform,   loader=safe_loader)\n",
    "test_ds  = datasets.ImageFolder(os.path.join(data_dir, \"test\"),  transform=val_transform,  loader=safe_loader)\n",
    "\n",
    "train_loader = DataLoader(train_ds, batch_size=32, shuffle=True, num_workers=4)\n",
    "val_loader   = DataLoader(val_ds, batch_size=32, shuffle=False, num_workers=4)\n",
    "test_loader  = DataLoader(test_ds, batch_size=32, shuffle=False, num_workers=4)\n",
    "\n",
    "num_classes = len(train_ds.classes)\n",
    "print(\"Total de classes:\", num_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a74d0bdc",
   "metadata": {},
   "source": [
    "## Carregar a ResNet50 pré-treinada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "49c5d741",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Carrega modelo ResNet50 já treinado com ImageNet (já sabefeatures gerais de imagens como bordas, textura, etc.)\n",
    "model = models.resnet50(weights=models.ResNet50_Weights.IMAGENET1K_V2)\n",
    "\n",
    "# Treina todas as camadas sem congelamento\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = True \n",
    "\n",
    "# Substituir a última camada de 1000 classes (ImageNet) para 30 do nosso problema (fine tunning)\n",
    "model.fc = nn.Linear(model.fc.in_features, num_classes)\n",
    "\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "feecd73c",
   "metadata": {},
   "source": [
    "## Otimizador, Loss e Scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b807c2c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss() # Função de Perda (Loss)\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-4) # Otimizador baseado em gradiente\n",
    "\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau( # ajusta a taxa de aprendizado se o progresso travar\n",
    "    optimizer, factor=0.5, patience=3\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d637fe1f",
   "metadata": {},
   "source": [
    "## Funções de treino e validação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "04b372a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch(model, loader, optimizer, criterion):\n",
    "    model.train()\n",
    "    total, correct, total_loss = 0, 0, 0\n",
    "\n",
    "    # itera sob s batches (conjunto de imagens)\n",
    "    for imgs, labels in tqdm(loader, desc=\"Treinando\"):\n",
    "        imgs, labels = imgs.to(device), labels.to(device) #carrega na cpu/gpu\n",
    "\n",
    "        optimizer.zero_grad() # reseta o gradiente\n",
    "        outputs = model(imgs) # obtém as classificações\n",
    "        loss = criterion(outputs, labels) # obtém as predições comparando com os labels e calcula o loss\n",
    "        \n",
    "        loss.backward() # calcula o gradiente da loss em relação aos pesos \n",
    "        optimizer.step() # atualiza os pesos com base no gradiente\n",
    "\n",
    "        # Métricas\n",
    "        total_loss += loss.item() * imgs.size(0)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        correct += (preds == labels).sum().item()\n",
    "        total += imgs.size(0)\n",
    "\n",
    "    return total_loss / total, correct / total\n",
    "\n",
    "\n",
    "def validate(model, loader, criterion):\n",
    "    model.eval()\n",
    "    total, correct, total_loss = 0, 0, 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for imgs, labels in tqdm(loader, desc=\"Validando\"):\n",
    "            imgs, labels = imgs.to(device), labels.to(device) # carrega\n",
    "            outputs = model(imgs) # avalia\n",
    "            loss = criterion(outputs, labels) # calcula a loss\n",
    "\n",
    "            # Métricas\n",
    "            total_loss += loss.item() * imgs.size(0)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            correct += (preds == labels).sum().item()\n",
    "            total += imgs.size(0)\n",
    "\n",
    "    return total_loss / total, correct / total"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6eabae5e",
   "metadata": {},
   "source": [
    "## Loop de treinamento com Early Stopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "89034776",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "1\n",
      "NVIDIA GeForce GTX 1650\n"
     ]
    }
   ],
   "source": [
    "print(torch.cuda.is_available())\n",
    "print(torch.cuda.device_count())\n",
    "print(torch.cuda.get_device_name(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "067fdb83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== Época 1/100 =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Treinando: 100%|██████████| 654/654 [05:53<00:00,  1.85it/s]\n",
      "Validando: 100%|██████████| 35/35 [00:05<00:00,  6.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Treino  Loss: 1.1256  Acc: 0.6722\n",
      "Validação Loss: 0.4350  Acc: 0.8689\n",
      "Modelo salvo (melhor até agora)\n",
      "\n",
      "===== Época 2/100 =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Treinando: 100%|██████████| 654/654 [05:55<00:00,  1.84it/s]\n",
      "Validando: 100%|██████████| 35/35 [00:05<00:00,  5.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Treino  Loss: 0.3224  Acc: 0.8979\n",
      "Validação Loss: 0.4071  Acc: 0.8816\n",
      "Modelo salvo (melhor até agora)\n",
      "\n",
      "===== Época 3/100 =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Treinando: 100%|██████████| 654/654 [05:55<00:00,  1.84it/s]\n",
      "Validando: 100%|██████████| 35/35 [00:05<00:00,  5.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Treino  Loss: 0.1687  Acc: 0.9466\n",
      "Validação Loss: 0.4371  Acc: 0.8861\n",
      "Modelo salvo (melhor até agora)\n",
      "\n",
      "===== Época 4/100 =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Treinando: 100%|██████████| 654/654 [05:47<00:00,  1.88it/s]\n",
      "Validando: 100%|██████████| 35/35 [00:05<00:00,  6.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Treino  Loss: 0.1068  Acc: 0.9678\n",
      "Validação Loss: 0.4700  Acc: 0.8816\n",
      "Early stopping counter: 1/6\n",
      "\n",
      "===== Época 5/100 =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Treinando: 100%|██████████| 654/654 [05:47<00:00,  1.88it/s]\n",
      "Validando: 100%|██████████| 35/35 [00:05<00:00,  6.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Treino  Loss: 0.0826  Acc: 0.9741\n",
      "Validação Loss: 0.4837  Acc: 0.8861\n",
      "Early stopping counter: 2/6\n",
      "\n",
      "===== Época 6/100 =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Treinando: 100%|██████████| 654/654 [05:45<00:00,  1.89it/s]\n",
      "Validando: 100%|██████████| 35/35 [00:05<00:00,  6.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Treino  Loss: 0.0675  Acc: 0.9796\n",
      "Validação Loss: 0.4633  Acc: 0.8915\n",
      "Modelo salvo (melhor até agora)\n",
      "\n",
      "===== Época 7/100 =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Treinando: 100%|██████████| 654/654 [05:41<00:00,  1.91it/s]\n",
      "Validando: 100%|██████████| 35/35 [00:05<00:00,  6.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Treino  Loss: 0.0264  Acc: 0.9926\n",
      "Validação Loss: 0.4729  Acc: 0.9014\n",
      "Modelo salvo (melhor até agora)\n",
      "\n",
      "===== Época 8/100 =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Treinando: 100%|██████████| 654/654 [05:41<00:00,  1.91it/s]\n",
      "Validando: 100%|██████████| 35/35 [00:05<00:00,  6.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Treino  Loss: 0.0144  Acc: 0.9958\n",
      "Validação Loss: 0.5387  Acc: 0.8978\n",
      "Early stopping counter: 1/6\n",
      "\n",
      "===== Época 9/100 =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Treinando: 100%|██████████| 654/654 [05:41<00:00,  1.91it/s]\n",
      "Validando: 100%|██████████| 35/35 [00:05<00:00,  6.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Treino  Loss: 0.0139  Acc: 0.9962\n",
      "Validação Loss: 0.5230  Acc: 0.9014\n",
      "Early stopping counter: 2/6\n",
      "\n",
      "===== Época 10/100 =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Treinando: 100%|██████████| 654/654 [05:41<00:00,  1.92it/s]\n",
      "Validando: 100%|██████████| 35/35 [00:05<00:00,  6.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Treino  Loss: 0.0160  Acc: 0.9955\n",
      "Validação Loss: 0.5504  Acc: 0.8852\n",
      "Early stopping counter: 3/6\n",
      "\n",
      "===== Época 11/100 =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Treinando: 100%|██████████| 654/654 [05:41<00:00,  1.92it/s]\n",
      "Validando: 100%|██████████| 35/35 [00:05<00:00,  6.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Treino  Loss: 0.0085  Acc: 0.9977\n",
      "Validação Loss: 0.5233  Acc: 0.9087\n",
      "Modelo salvo (melhor até agora)\n",
      "\n",
      "===== Época 12/100 =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Treinando: 100%|██████████| 654/654 [05:40<00:00,  1.92it/s]\n",
      "Validando: 100%|██████████| 35/35 [00:05<00:00,  6.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Treino  Loss: 0.0064  Acc: 0.9982\n",
      "Validação Loss: 0.5442  Acc: 0.9078\n",
      "Early stopping counter: 1/6\n",
      "\n",
      "===== Época 13/100 =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Treinando: 100%|██████████| 654/654 [05:41<00:00,  1.92it/s]\n",
      "Validando: 100%|██████████| 35/35 [00:05<00:00,  6.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Treino  Loss: 0.0060  Acc: 0.9985\n",
      "Validação Loss: 0.5458  Acc: 0.9014\n",
      "Early stopping counter: 2/6\n",
      "\n",
      "===== Época 14/100 =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Treinando: 100%|██████████| 654/654 [05:41<00:00,  1.92it/s]\n",
      "Validando: 100%|██████████| 35/35 [00:05<00:00,  6.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Treino  Loss: 0.0057  Acc: 0.9985\n",
      "Validação Loss: 0.5517  Acc: 0.9014\n",
      "Early stopping counter: 3/6\n",
      "\n",
      "===== Época 15/100 =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Treinando: 100%|██████████| 654/654 [05:40<00:00,  1.92it/s]\n",
      "Validando: 100%|██████████| 35/35 [00:05<00:00,  6.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Treino  Loss: 0.0037  Acc: 0.9991\n",
      "Validação Loss: 0.5395  Acc: 0.9033\n",
      "Early stopping counter: 4/6\n",
      "\n",
      "===== Época 16/100 =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Treinando: 100%|██████████| 654/654 [05:40<00:00,  1.92it/s]\n",
      "Validando: 100%|██████████| 35/35 [00:05<00:00,  6.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Treino  Loss: 0.0026  Acc: 0.9995\n",
      "Validação Loss: 0.5379  Acc: 0.9051\n",
      "Early stopping counter: 5/6\n",
      "\n",
      "===== Época 17/100 =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Treinando: 100%|██████████| 654/654 [05:40<00:00,  1.92it/s]\n",
      "Validando: 100%|██████████| 35/35 [00:05<00:00,  6.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Treino  Loss: 0.0024  Acc: 0.9995\n",
      "Validação Loss: 0.5318  Acc: 0.9060\n",
      "Early stopping counter: 6/6\n",
      "Early stopping ativado\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 1\n",
    "best_val_acc = 0\n",
    "patience = 6\n",
    "wait = 0\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    print(f\"\\n===== Época {epoch+1}/{EPOCHS} =====\")\n",
    "\n",
    "    train_loss, train_acc = train_one_epoch(model, train_loader, optimizer, criterion)\n",
    "    val_loss, val_acc = validate(model, val_loader, criterion)\n",
    "\n",
    "    print(f\"Treino  Loss: {train_loss:.4f}  Acc: {train_acc:.4f}\")\n",
    "    print(f\"Validação Loss: {val_loss:.4f}  Acc: {val_acc:.4f}\")\n",
    "\n",
    "    scheduler.step(val_loss)\n",
    "\n",
    "    # Early stopping\n",
    "    if val_acc > best_val_acc:\n",
    "        best_val_acc = val_acc\n",
    "        wait = 0\n",
    "        torch.save(model.state_dict(), os.path.join(TRAINED_MODELS_FOLDER,\"best_resnet50.pth\"))\n",
    "        print(\"Modelo salvo (melhor até agora)\")\n",
    "    else:\n",
    "        wait += 1\n",
    "        print(f\"Early stopping counter: {wait}/{patience}\")\n",
    "\n",
    "    if wait >= patience:\n",
    "        print(\"Early stopping ativado\")\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1aa1d3d9",
   "metadata": {},
   "source": [
    "## Avaliar no conjunto de teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f5969bd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validando: 100%|██████████| 36/36 [00:05<00:00,  6.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "RESULTADO FINAL NO TESTE:\n",
      "Acurácia: 0.9027\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model.load_state_dict(torch.load(\"best_resnet50.pth\"))\n",
    "test_loss, test_acc = validate(model, test_loader, criterion)\n",
    "print(\"\\nRESULTADO FINAL NO TESTE:\")\n",
    "print(f\"Acurácia: {test_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f00d413",
   "metadata": {},
   "source": [
    "## Avaliar um classe específica do conjunto de testes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8de1d840",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Classe: Gobio gobio -> índice: 12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validando: 100%|██████████| 2/2 [00:00<00:00,  6.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== RESULTADOS PARA A CLASSE 'Gobio gobio' ===\n",
      "Acurácia: 0.9143\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import Subset\n",
    "\n",
    "\n",
    "classe_escolhida = \"Gobio gobio\"\n",
    "\n",
    "# pega o índice da classe\n",
    "idx_classe = test_ds.class_to_idx[classe_escolhida]\n",
    "print(\"[INFO] Classe:\", classe_escolhida, \"-> índice:\", idx_classe)\n",
    "\n",
    "# filtra apenas imagens dessa classe\n",
    "indices = [i for i, (_, lab) in enumerate(test_ds.samples) if lab == idx_classe]\n",
    "\n",
    "# cria um subset\n",
    "subset_classe = Subset(test_ds, indices)\n",
    "\n",
    "# loader só dessa classe\n",
    "test_loader_classe = torch.utils.data.DataLoader(\n",
    "    subset_classe, batch_size=32, shuffle=False, num_workers=4\n",
    ")\n",
    "\n",
    "# avaliação\n",
    "model.load_state_dict(torch.load(\"best_resnet50.pth\"))\n",
    "loss, acc = validate(model, test_loader_classe, criterion)\n",
    "\n",
    "print(f\"\\n=== RESULTADOS PARA A CLASSE '{classe_escolhida}' ===\")\n",
    "print(f\"Acurácia: {acc:.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
